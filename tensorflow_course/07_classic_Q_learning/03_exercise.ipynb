{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f70e03",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'><img src='../COURSE_NOTEBOOKS/Pierian_Data_Logo.png'/></a>\n",
    "___\n",
    "<center><em>Copyright by Pierian Data Inc.</em></center>\n",
    "<center><em>For more information, visit us at <a href='http://www.pieriandata.com'>www.pieriandata.com</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a938939",
   "metadata": {},
   "source": [
    "# Q Learning Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c5575",
   "metadata": {},
   "source": [
    "**We'll be reviewing and testing your skills with Q-Learning on a continuous space! Please feel free to reference the lecture notebooks you are definitely not expected to be able to fill out all this code from memory, just the ability to understand the core concepts and apply it to a different situation.**\n",
    "\n",
    "--------------------\n",
    "\n",
    "## Complete the tasks in bold below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147ae69",
   "metadata": {},
   "source": [
    "In this exercise we take a look at the MountainCar-v0 (https://gym.openai.com/envs/MountainCar-v0/) game again. That is the game from our original discussion of OpenAi gym environments for which we created an agent manually.\n",
    "Remember, that the goal is to reach the top of the mountain within some time limit\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8b2ce",
   "metadata": {},
   "source": [
    "**TASK: Import any relevant libraries you think you might need.** <br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e0d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f7e28",
   "metadata": {},
   "source": [
    "**TASK: Create the gym mountain car environment** <br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d001763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tobia\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171192c3",
   "metadata": {},
   "source": [
    "**TASK: Write a function to create a numpy array holding the bins for the observations of the car (position and velocity).** <br />\n",
    "Feel free to explore different bins per observation spacings.\n",
    "The function should take one argument which acts as the bins per observation <br />\n",
    "Hint: You can find the observations here: https://github.com/openai/gym/blob/master/gym/envs/classic_control/mountain_car.py\n",
    "<br /> Hint: You will probably need around 25 bins for good results, but feel free to use less to reduce training time. <br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5519e87",
   "metadata": {},
   "source": [
    "exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686b1c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3713549   0.01236658]\n",
      "[-0.6485203  -0.01170497]\n"
     ]
    }
   ],
   "source": [
    "# check the env's values\n",
    "env.reset()\n",
    "\n",
    "obs = []\n",
    "\n",
    "for step in range(100):\n",
    "    observations, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "    obs += [observations]\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(np.max(obs, axis=0))\n",
    "print(np.min(obs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e0ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bins(num_bins_per_observation):\n",
    "    # position\n",
    "    # -inf, inf\n",
    "    discrete_position = np.linspace(-1.2, 0.6, num_bins_per_observation)\n",
    "\n",
    "    # velocity\n",
    "    discrete_velocity = np.linspace(-0.07, 0.07, num_bins_per_observation)\n",
    "\n",
    "    bins = np.array([discrete_position,\n",
    "                    discrete_velocity])\n",
    "\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16f6a1",
   "metadata": {},
   "source": [
    "**TASK: Here you should write the code which creates the bins and defines the NUM_BINS attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b2b0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2       , -1.125     , -1.05      , -0.975     , -0.9       ,\n",
       "        -0.825     , -0.75      , -0.675     , -0.6       , -0.525     ,\n",
       "        -0.45      , -0.375     , -0.3       , -0.225     , -0.15      ,\n",
       "        -0.075     ,  0.        ,  0.075     ,  0.15      ,  0.225     ,\n",
       "         0.3       ,  0.375     ,  0.45      ,  0.525     ,  0.6       ],\n",
       "       [-0.07      , -0.06416667, -0.05833333, -0.0525    , -0.04666667,\n",
       "        -0.04083333, -0.035     , -0.02916667, -0.02333333, -0.0175    ,\n",
       "        -0.01166667, -0.00583333,  0.        ,  0.00583333,  0.01166667,\n",
       "         0.0175    ,  0.02333333,  0.02916667,  0.035     ,  0.04083333,\n",
       "         0.04666667,  0.0525    ,  0.05833333,  0.06416667,  0.07      ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_BINS = 25\n",
    "BINS = create_bins(NUM_BINS)\n",
    "BINS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28446881",
   "metadata": {},
   "source": [
    "**TASK: Create a function that will take in observations from the environment and the bins array and return the discretized version of the observation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcceedae",
   "metadata": {},
   "source": [
    "Now we need the code to discretize the observations. We can use the same code as used in the last notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6365d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_observation(observations, bins):\n",
    "    # can be implemented with a for-loop as well\n",
    "    binned_observations = []\n",
    "\n",
    "    discrete_position = np.digitize(observations[0], bins[0]) \n",
    "    binned_observations += [discrete_position]\n",
    "\n",
    "    discrete_velocity = np.digitize(observations[1], bins[1]) \n",
    "    binned_observations += [discrete_velocity]\n",
    "\n",
    "    return tuple(binned_observations) # Important for later indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176faaf",
   "metadata": {},
   "source": [
    "**Let's check to make sure your previous two function calls work with a quick task! Otherwise it may be hard to debug later on.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d8d8e",
   "metadata": {},
   "source": [
    "**TASK: Confirm that your *create_bins()* function works with *discretize_observation() by running the following cell***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5eca009",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bins = create_bins(5)\n",
    "np.testing.assert_almost_equal(test_bins[0], [-1.2 , -0.75, -0.3 ,  0.15,  0.6])\n",
    "np.testing.assert_almost_equal(test_bins[1], [-0.07 , -0.035,  0.   ,  0.035,  0.07 ])\n",
    "\n",
    "test_observation = np.array([-0.9, 0.03])\n",
    "discretized_test_bins = discretize_observation(test_observation, test_bins)\n",
    "assert discretized_test_bins == (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e71a8",
   "metadata": {},
   "source": [
    "**TASK: Create the Q-Table** <br />\n",
    "Remember the shape that the Q-Table needs to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b9bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE Q TABLE\n",
    "q_table_shape = (NUM_BINS, NUM_BINS, env.action_space.n)\n",
    "q_table = np.zeros(q_table_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d485ec",
   "metadata": {},
   "source": [
    "**TASK: Fill out the Epislon Greedy Action Selection function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac943d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action_selection(epsilon, q_table, discrete_state):\n",
    "    random_number = np.random.rand()\n",
    "    if epsilon < random_number:\n",
    "        action = np.argmax(q_table[discrete_state])\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "        # action = np.random.randint(0, env.action_space.n)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f5ec4",
   "metadata": {},
   "source": [
    "**TASK: Fill out the function to compute the next Q value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ec635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_next_q_value(old_q_value, reward, next_optimal_q_value):\n",
    "    return old_q_value + ALPHA * (reward + GAMMA*next_optimal_q_value - old_q_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043548dc",
   "metadata": {},
   "source": [
    "**TASK: Create a function to reduce epsilon, feel free to choose any reduction method you want. We'll use a reduction with BURN_IN and EPSILON_END limits in the solution. We'll also show a way to reduce epsilon based on the number of epochs. Feel free to experiment here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea236a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_epsilon(epsilon, epoch):\n",
    "    if BURN_IN <= epsilon <= EPSILON_END:\n",
    "        epsilon -= EPSILON_REDUCE\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2631b38",
   "metadata": {},
   "source": [
    "**TASK: Define your hyperparameters. Note, we'll show our solution hyperparameters here, but depending on your *reduce_epsilon* function, your epsilon hyperparameters may be different.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60825d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to change!\n",
    "\n",
    "EPOCHS = 30000\n",
    "BURN_IN = 100\n",
    "epsilon = 1\n",
    "\n",
    "EPSILON_END= 25000\n",
    "EPSILON_REDUCE = 0.000001 \n",
    "\n",
    "ALPHA = 0.8\n",
    "GAMMA = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73abcf6",
   "metadata": {},
   "source": [
    "**TASK: Create the training loop for the reinforcement learning agent and run the loop. We've gone ahead and created the basic structure of the loopwith some comments. We also pre-filled the visualization portion.** <br />\n",
    "Note: Use the lecture notebook as a guide and reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d671a646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_table = np.zeros(q_table_shape)\n",
    "epsilon = 1\n",
    "\n",
    "####### VISUALIZATION CODE FOR YOU. TOTALLY OPTIONAL. ##########################\n",
    "########## FEEL FREE TO REMOVE OR ADD YOUR OWN VISUAL CODE. #################\n",
    "\n",
    "log_interval = 100  # How often do we update the plot? (Just for performance reasons)\n",
    "### Here we set up the routine for the live plotting of the achieved points ######\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.canvas.draw()\n",
    "\n",
    "max_position_log = []  # to store all achieved points\n",
    "mean_positions_log = []  # to store a running mean of the last 30 results\n",
    "epochs = []  # store the epoch for plotting\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "################################## TRAINING TASKS ##########################\n",
    "###########################################################################\n",
    "for epoch in range(EPOCHS):\n",
    "    ################################# TODO ######################################\n",
    "    \n",
    "    # TODO: Get initial observation and discretize them. Set done to False\n",
    "    #########################################\n",
    "    initial_observation = env.reset()\n",
    "    discrete_state = discretize_observation(initial_observation, BINS)\n",
    "    done = False\n",
    "    ##########################################\n",
    "    \n",
    "    #############################\n",
    "    # These lines are for plotting.\n",
    "    max_position = -np.inf  \n",
    "    epochs.append(epoch)\n",
    "    #############################\n",
    "    \n",
    "    # TASK TO DO: As long as current run is alive (i.e not done) perform the following steps:\n",
    "    while not done:  # Perform current run as long as done is False (as long as there is still time to reach the top)\n",
    "\n",
    "        ##########################################\n",
    "        # TASK TO DO: Select action according to epsilon-greedy strategy\n",
    "        #########################################\n",
    "        action = epsilon_greedy_action_selection(epsilon, q_table, discrete_state)\n",
    "\n",
    "        ##########################################\n",
    "        # TASK TO DO: Perform selected action and get next state. Do not forget to discretize it\n",
    "        #########################################\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        discretized_next_state = discretize_observation(next_state, BINS)\n",
    "\n",
    "        ##########################################\n",
    "        # TASK TO DO: Get old Q-value from Q-Table and get next optimal Q-Value\n",
    "        #########################################\n",
    "        old_q_value = q_table[discrete_state + (action,)]\n",
    "        next_optimal_q_value = np.argmax(q_table[discretized_next_state + (action,)])\n",
    "\n",
    "        ##########################################\n",
    "        # TASK TO DO: Compute next Q-Value and insert it into the table\n",
    "        #########################################\n",
    "        next_q = compute_next_q_value(old_q_value, reward, next_optimal_q_value)\n",
    "        q_table[discrete_state + (action,)] = next_q\n",
    "\n",
    "        ##########################################\n",
    "        # TASK TO DO: Update the old state with the new one\n",
    "        #########################################\n",
    "        discrete_state = discretized_next_state\n",
    "\n",
    "        ##########################################\n",
    "        \n",
    "        \n",
    "        ##############################\n",
    "        ##  Only for plotting the results - store the highest point the car is able to reach\n",
    "        position = discretized_next_state[0]  #next_state[0]\n",
    "        if position > max_position:  \n",
    "            max_position = position\n",
    "\n",
    "    # TASK TO DO: Reduce epsilon\n",
    "    #########################################\n",
    "    epsilon = reduce_epsilon(epsilon, epoch)\n",
    "    ##########################################\n",
    "    ##############################################################################\n",
    "\n",
    "    max_position_log.append(max_position)  # log the highest position the car was able to reach\n",
    "    running_mean = round(np.mean(max_position_log[-30:]), 2)  # Compute running mean of position over the last 30 epochs\n",
    "    mean_positions_log.append(running_mean)  # and log it\n",
    "    \n",
    "    ################ Plot the points and running mean ##################\n",
    "    if epoch % log_interval == 0:\n",
    "        ax.clear()\n",
    "        ax.scatter(epochs, max_position_log)\n",
    "        ax.plot(epochs, max_position_log)\n",
    "        ax.plot(epochs, mean_positions_log, label=f\"Running Mean: {running_mean}\")\n",
    "        plt.legend()\n",
    "        fig.canvas.draw()\n",
    "  ######################################################################\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe063fab",
   "metadata": {},
   "source": [
    "**(numpy) what means array[i + (j,)]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b18c7a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(1, 10).reshape(3, 3)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e7397e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3911ee45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2b865df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64cf68c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[(0,) + (0,)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5bcac",
   "metadata": {},
   "source": [
    "=> with 'q_table[discrete_state + (action,)]' we adding the action to the state, so we have all indexes to get to a value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5de67a",
   "metadata": {},
   "source": [
    "**TASK: Use your Q-Table to test your agent and render its performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39fbe789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's done! Reward = -1.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "observation = env.reset()\n",
    "\n",
    "for step in range(10000):\n",
    "    env.render()\n",
    "    # get the action with max q_value\n",
    "    discretized_observation = discretize_observation(observation, BINS)\n",
    "    action = np.argmax(q_table[discretized_observation])\n",
    "    # make turn\n",
    "    observation, reward, done, info = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        print(f\"It's done! Reward = {reward}\")\n",
    "        break\n",
    "\n",
    "    time.sleep(0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77b6e7",
   "metadata": {},
   "source": [
    "**OPTIONAL: Play with our Q-Table with 40 bins per observation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831daba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saved our matrix q_table for you (with 40 bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e16f226",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '40bin_qtable_mountaincar.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8542a3579a89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mour_q_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'40bin_qtable_mountaincar.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '40bin_qtable_mountaincar.npy'"
     ]
    }
   ],
   "source": [
    "our_q_table = np.load('40bin_qtable_mountaincar.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832a448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_q_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1045da",
   "metadata": {},
   "source": [
    "**Great job! Note how you could train for many more epochs/episodes or edit hyperparameters, the more complex the environment, the more choices you have to experiment with!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f261d6473f1dd2b46c53affda8b45565a09c2039f31152146d1a5fcb65cff0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
