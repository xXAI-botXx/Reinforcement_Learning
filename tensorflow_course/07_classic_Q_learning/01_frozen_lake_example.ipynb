{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frozen Lake Game with Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#import os    # os.system('cls')\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**set up gym env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a new custom version of FrozenLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register\n",
    "\n",
    "try:\n",
    "    register(\n",
    "        id='FrozenLakeNotSlippery-v0',\n",
    "        entry_point='gym-envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={'map_name':'4x4', 'is_slippery':False},\n",
    "        max_episode_steps=100,\n",
    "        reward_threshold=0.78#, optimum=0.8196\n",
    "    )\n",
    "except:\n",
    "    print('Already registered!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**run env**\n",
    "\n",
    "for example with random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=False)\n",
    "env.reset()\n",
    "\n",
    "for step in range(15):\n",
    "    env.render(mode='human')#mode='human')\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    time.sleep(0.5)\n",
    "    #clear_output(wait=True)\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create q-table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n\n",
    "q_table = np.zeros([state_size, action_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1*10^-5\n",
    "1e-5 == 0.00001 == 1*10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e5 == 100000 == 1*10**5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hyperparameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many times the agent plays the game\n",
    "EPOCHS = 20000 # Episodes\n",
    "\n",
    "# learning rate\n",
    "ALPHA = 0.8\n",
    "\n",
    "# discount-rate\n",
    "# should be a little smaller than 1\n",
    "GAMMA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eploration rate\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "# reducing exploration by rate:\n",
    "decay_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**defining update functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action_selection(epsilon, q_table, discrete_state):\n",
    "    random_number = np.random.random()\n",
    "\n",
    "    # EXPLOTATION (choose the action that maximizes Q)\n",
    "    if random_number > epsilon:\n",
    "        \n",
    "        state_row = q_table[discrete_state, :]\n",
    "        action = np.argmax(state_row)\n",
    "\n",
    "    # EXPLORATION (choose a random action)\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_next_q_value(old_q_value, reward, next_optimal_q_value):\n",
    "    return old_q_value + ALPHA * (reward + GAMMA*next_optimal_q_value - old_q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_epsilon(epsilon, epoch):\n",
    "    return min_epsilon + (max_epsilon-min_epsilon)*np.exp(-decay_rate*epoch)\n",
    "    #return epsilon -= 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**agent training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normal version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed rewards =  0.0\n",
      "Summed rewards =  272.0\n",
      "Summed rewards =  980.0\n",
      "Summed rewards =  1890.0\n",
      "Summed rewards =  2849.0\n",
      "Summed rewards =  3825.0\n",
      "Summed rewards =  4813.0\n",
      "Summed rewards =  5801.0\n",
      "Summed rewards =  6788.0\n",
      "Summed rewards =  7777.0\n",
      "Summed rewards =  8761.0\n",
      "Summed rewards =  9745.0\n",
      "Summed rewards =  10734.0\n",
      "Summed rewards =  11722.0\n",
      "Summed rewards =  12710.0\n",
      "Summed rewards =  13701.0\n",
      "Summed rewards =  14684.0\n",
      "Summed rewards =  15680.0\n",
      "Summed rewards =  16672.0\n",
      "Summed rewards =  17654.0\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "log_interval = 1000\n",
    "\n",
    "for episode in range(EPOCHS):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "\n",
    "    while not done:\n",
    "        # CHOOSE ACTION\n",
    "        action = epsilon_greedy_action_selection(epsilon, q_table, discrete_state=state)\n",
    "\n",
    "        # PERFORM ACTION\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # OLD (current) Q VALUE\n",
    "        old_q_value = q_table[state, action]\n",
    "\n",
    "        # Get next optimal Q Value (max Q value for this state) Q(st+1, at+1)\n",
    "        #           we want the value, not the action/index\n",
    "        next_optimal_q_value = np.max(q_table[new_state, :])\n",
    "\n",
    "        # Compute the next Q Value\n",
    "        next_q_value = compute_next_q_value(old_q_value, reward, next_optimal_q_value)\n",
    "\n",
    "        # Update the table\n",
    "        q_table[state, action] = next_q_value\n",
    "\n",
    "        # track rewards\n",
    "        total_rewards += reward\n",
    "\n",
    "        # new_state is now state\n",
    "        state = new_state\n",
    "\n",
    "    # agent finished a round on the game\n",
    "    #episode += 1\n",
    "    epsilon = reduce_epsilon(epsilon, episode)\n",
    "    rewards += [total_rewards]\n",
    "\n",
    "    if episode % log_interval == 0:\n",
    "        print(\"Summed rewards = \", np.sum(rewards))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualized version:\n",
    "\n",
    "don't works in VSCode maybe it works in Jupyter-Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([state_size, action_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "rewards = []\n",
    "log_interval = 1000\n",
    "\n",
    "########################\n",
    "fig = plt.figure()\n",
    "axes = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.canvas.draw()\n",
    "epoch_plot_tracker = []\n",
    "total_reward_plot_tracker = []\n",
    "########################\n",
    "\n",
    "for episode in range(EPOCHS):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "\n",
    "    while not done:\n",
    "        # CHOOSE ACTION\n",
    "        action = epsilon_greedy_action_selection(epsilon, q_table, discrete_state=state)\n",
    "\n",
    "        # PERFORM ACTION\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # OLD (current) Q VALUE\n",
    "        old_q_value = q_table[state, action]\n",
    "\n",
    "        # Get next optimal Q Value (max Q value for this state) Q(st+1, at+1)\n",
    "        #           we want the value, not the action/index\n",
    "        next_optimal_q_value = np.max(q_table[new_state, :])\n",
    "\n",
    "        # Compute the next Q Value\n",
    "        next_q_value = compute_next_q_value(old_q_value, reward, next_optimal_q_value)\n",
    "\n",
    "        # Update the table\n",
    "        q_table[state, action] = next_q_value\n",
    "\n",
    "        # track rewards\n",
    "        total_rewards += reward\n",
    "\n",
    "        # new_state is now state\n",
    "        state = new_state\n",
    "\n",
    "    # agent finished a round on the game\n",
    "    #episode += 1\n",
    "    epsilon = reduce_epsilon(epsilon, episode)\n",
    "    rewards += [total_rewards]\n",
    "\n",
    "    ########################\n",
    "    total_reward_plot_tracker += [np.sum(rewards)]\n",
    "    epoch_plot_tracker += [episode]\n",
    "    if episode % log_interval == 0:\n",
    "        axes.clear()\n",
    "        axes.plot(epoch_plot_tracker, total_reward_plot_tracker)\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "    ########################\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**use trained agent** (utilization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.531441, 0.59049 , 0.59049 , 0.531441],\n",
       "       [0.531441, 0.      , 0.6561  , 0.59049 ],\n",
       "       [0.59049 , 0.729   , 0.59049 , 0.6561  ],\n",
       "       [0.6561  , 0.      , 0.59049 , 0.59049 ],\n",
       "       [0.59049 , 0.6561  , 0.      , 0.531441],\n",
       "       [0.      , 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.81    , 0.      , 0.6561  ],\n",
       "       [0.      , 0.      , 0.      , 0.      ],\n",
       "       [0.6561  , 0.      , 0.729   , 0.59049 ],\n",
       "       [0.6561  , 0.81    , 0.81    , 0.      ],\n",
       "       [0.729   , 0.9     , 0.      , 0.729   ],\n",
       "       [0.      , 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.81    , 0.9     , 0.729   ],\n",
       "       [0.81    , 0.9     , 1.      , 0.81    ],\n",
       "       [0.      , 0.      , 0.      , 0.      ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\tobia\\.conda\\envs\\ai\\lib\\site-packages\\gym\\core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=False)\n",
    "state = env.reset()\n",
    "\n",
    "for steps in range(100):\n",
    "    env.render()\n",
    "    action = np.argmax(q_table[state, :])\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    # clear_output(wait=True)\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f261d6473f1dd2b46c53affda8b45565a09c2039f31152146d1a5fcb65cff0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
